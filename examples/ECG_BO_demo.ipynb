{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f15fbd76",
   "metadata": {},
   "source": [
    "### Create geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97c1b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859eeca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run on jupyter\n",
    "patient_number       = \"demo\"\n",
    "N                    = 250 # 3 #\n",
    "obtain_training_data = \"compute_points\" #\n",
    "nIter                = 300 # 2 #\n",
    "criterion_bo         = \"EI\" # \"LCB\" # \"LW-LCB\"\n",
    "optimization_points  =   \"run_opt\" # \"load_opt_points\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3710bf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ( \"#####################################\")\n",
    "print (f\"Running analysis of patient {patient_number}\")\n",
    "print (f\"N = {N}, {obtain_training_data}            \") \n",
    "print (f\"nIter = {nIter}, {optimization_points}  \")\n",
    "print ( \"#####################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f986ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bo_purkinje_tree import BO_PurkinjeTree\n",
    "from myocardial_mesh import MyocardialMesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12dedfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bo_ecg import BO_ecg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d60ac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as onp\n",
    "import jax.numpy as np\n",
    "import jax\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "from jax import random, lax\n",
    "from jaxbo.models import GP\n",
    "from jaxbo.utils import normalize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from jax import ops\n",
    "from scipy.stats import norm\n",
    "\n",
    "onp.random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059ba6b9",
   "metadata": {},
   "source": [
    "### Create reference tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54696f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "if patient_number == \"demo\":\n",
    "    patient = \"../data/crtdemo/crtdemo\"\n",
    "#     qrs_in, qrs_fin = 200, 400\n",
    "    meshes_list_pat = [388, 412, 198, 186] # These are node indices (of the LV and RV endocardial meshes) that determine the direction of the\n",
    "                                           # initial branch of the Purkinje Tree\n",
    "                                           # Here, 388 and 412 are nodes of the LV endocardial mesh and\n",
    "                                           #       198 and 186 are nodes of the RV endocardial mesh\n",
    "    myo = MyocardialMesh(myo_mesh            = f\"{patient}_mesh_oriented.vtk\",\n",
    "                    electrodes_position = f\"PurkinjeECG/data/crtdemo/electrode_pos.pkl\",\n",
    "                    fibers              = f\"{patient}_f0_oriented.vtk\",\n",
    "                    device = 'cpu') # or 'gpu' is available\n",
    "\n",
    "else:\n",
    "    raise Exception(\"patient_number must be 'demo'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1e4418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo\n",
    "true_parameters_values = {\"patient\"         : patient,\n",
    "                          \"meshes_list\"     : meshes_list_pat, \n",
    "                          \"init_length\"     : 0., \n",
    "                          \"length\"          : 8.,\n",
    "                          \"w\"               : 0.1, \n",
    "                          \"l_segment\"       : 1.,\n",
    "                          \"fascicles_length\": 0., \n",
    "                          \"fascicles_angles\": 0., \n",
    "                          \"branch_angle\"    : 0.15,\n",
    "                          \"N_it\"            : 20,\n",
    "                          \"myocardium\"      : myo}\n",
    "\n",
    "Tree_true      = BO_PurkinjeTree(**true_parameters_values)\n",
    "bo_method_true = BO_ecg(bo_purkinje_tree = Tree_true)\n",
    "\n",
    "if not os.path.exists(\"./output/patient\"+str(patient_number)):\n",
    "    os.makedirs(\"./output/patient\"+str(patient_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774dcba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Reading results of patient 1 ...\")\n",
    "if patient_number == \"demo\":\n",
    "    X_read = onp.load(\"PurkinjeECG/output/patient1/data_X_N_250_nIter_300_criterionEI_init_length_fascicles_length_fascicles_angles_root_time_cv.npy\")\n",
    "\n",
    "    y_read = onp.load(\"PurkinjeECG/output/patient1/data_y_N_250_nIter_300_criterionEI_init_length_fascicles_length_fascicles_angles_root_time_cv.npy\")\n",
    "    \n",
    "    X_min = X_read[onp.argmin(y_read)]\n",
    "    y_min = onp.min(y_read)\n",
    "    \n",
    "\n",
    "var_params_true = {\"init_length\"     : [X_min[0], X_min[1]],\n",
    "                   \"fascicles_length\": [[0.5*X_min[2], 0.5*X_min[3]],\n",
    "                                        [0.5*X_min[4], 0.5*X_min[5]]],\n",
    "                   \"fascicles_angles\": [[0.1*X_min[6], 0.1*X_min[7]],\n",
    "                                        [0.1*X_min[8], 0.1*X_min[9]]],\n",
    "                   \"root_time\"       : X_min[10],\n",
    "                   \"cv\"              : X_min[11]}\n",
    "\n",
    "\n",
    "\n",
    "print (\"Ground truth\")\n",
    "print (f\"X_ground_truth: {var_params_true}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fea0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_true, LVtree_true, RVtree_true = bo_method_true.bo_purkinje_tree.run_ECG(n_sim=0, modify=True, side='both', **var_params_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save true trees and endo\n",
    "file_name = f\"./output/patient{patient_number}/\"\n",
    "\n",
    "pickle.dump(ecg_true, open(f\"./output/patient{patient_number}/True_ecg\",\"wb\"))\n",
    "myo.save_pv(file_name+\"True_endo.vtu\")\n",
    "LVtree_true.save(file_name+\"True_LVtree.vtu\")\n",
    "RVtree_true.save(file_name+\"True_RVtree.vtu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrs_in, qrs_fin = 0, len (ecg_true) # in this case we will use the full ecgs\n",
    "ecg_pat_array = ecg_true[qrs_in:qrs_fin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reference_ecg = True\n",
    "\n",
    "if plot_reference_ecg:\n",
    "    fig,axs = plt.subplots(3, 4, figsize=(10,13), dpi=120, sharex=True, sharey=True)\n",
    "    for ax,l in zip(axs.ravel(),ecg_pat_array.dtype.names):\n",
    "        ax.plot(ecg_pat_array[l])\n",
    "        ax.grid()\n",
    "        ax.set_title(l)\n",
    "    #     ax.legend()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: In bo_ecg.calculate_loss(), cut_fin = 0, as here we compare the full ecgs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian optimization (with jaxbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 2\n",
    "\n",
    "def var_parameters_dict(var_parameters_names):\n",
    "    # Parameters to find\n",
    "    var_parameters = {}\n",
    "    \n",
    "    # init_length\n",
    "    if \"init_length\" in var_parameters_names:\n",
    "        lb_init_length                = 30.0 * onp.ones(dim)\n",
    "        ub_init_length                = 100.0 * onp.ones(dim)\n",
    "        var_parameters[\"init_length\"] = [lb_init_length, ub_init_length, \"uniform\"]\n",
    "\n",
    "    # length\n",
    "    if \"length\" in var_parameters_names:\n",
    "        lb_length                = 4. * onp.ones(1)\n",
    "        ub_length                = 12. * onp.ones(1)\n",
    "        var_parameters[\"length\"] = [lb_length, ub_length, \"uniform\"]\n",
    "\n",
    "    # w\n",
    "    if \"w\" in var_parameters_names:\n",
    "        lb_w                = 0.05* onp.ones(1) # 0.05\n",
    "        ub_w                = 0.25 * onp.ones(1) # 0.8\n",
    "        var_parameters[\"w\"] = [lb_w, ub_w, \"uniform\"]\n",
    "\n",
    "    # l_segment\n",
    "    if \"l_segment\" in var_parameters_names:\n",
    "        lb_l_segment                = 1. * onp.ones(dim)\n",
    "        ub_l_segment                = 15. * onp.ones(dim)\n",
    "        var_parameters[\"l_segment\"] = [lb_l_segment, ub_l_segment, \"uniform\"]\n",
    "\n",
    "    # fascicles_length\n",
    "    if \"fascicles_length\" in var_parameters_names:\n",
    "        lb_fascicles_length                = 2.0 * onp.ones(2*dim) # 10 # 2.*dim because there are 2 params per ventricle \n",
    "        ub_fascicles_length                = 50.0 * onp.ones(2*dim) # 30\n",
    "        var_parameters[\"fascicles_length\"] = [lb_fascicles_length, ub_fascicles_length, \"uniform\"]\n",
    "\n",
    "    # f_angles\n",
    "    if \"fascicles_angles\" in var_parameters_names:\n",
    "        lb_fascicles_angles                = -1./4. * onp.pi * np.ones(2*dim) # 0.1 # 2.*dim because there are 2 params per ventricle \n",
    "        ub_fascicles_angles                =  3./4. * onp.pi * np.ones(2*dim) # 1.57\n",
    "        var_parameters[\"fascicles_angles\"] = [lb_fascicles_angles, ub_fascicles_angles, \"uniform\"]\n",
    "\n",
    "    # branch_angle\n",
    "    if \"branch_angle\" in var_parameters_names:\n",
    "        lb_branch_angle                = 5. * onp.pi/180. * np.ones(1)\n",
    "        ub_branch_angle                = 45. * onp.pi/180. * np.ones(1)\n",
    "        var_parameters[\"branch_angle\"] = [lb_branch_angle, ub_branch_angle, \"uniform\"]\n",
    "    \n",
    "    # root_time\n",
    "    if \"root_time\" in var_parameters_names:\n",
    "        lb_root_time                = -75. * np.ones(1)\n",
    "        ub_root_time                = 50. * np.ones(1)\n",
    "        var_parameters[\"root_time\"] = [lb_root_time, ub_root_time, \"uniform\"]\n",
    "        \n",
    "    # cv\n",
    "    if \"cv\" in var_parameters_names:\n",
    "        lb_cv                = 2. * np.ones(1)\n",
    "        ub_cv                = 4. * np.ones(1)\n",
    "        var_parameters[\"cv\"] = [lb_cv, ub_cv, \"uniform\"]\n",
    "        \n",
    "    return var_parameters\n",
    "\n",
    "\n",
    "def initial_values(var_parameters_names, patient, meshes_list_pat, myocardium):\n",
    "    # Initial values for known parameters    \n",
    "    meshes_list  = meshes_list_pat\n",
    "    init_length  = 30\n",
    "    length       = 8. # [mm]\n",
    "    w            = 0.1\n",
    "    l_segment    = 1.0\n",
    "\n",
    "    f_len        = [20.0, 20.0] \n",
    "    f_angles     = [1., 1.] \n",
    "\n",
    "    branch_angle = 0.15 #20. * onp.pi/180. #0.15\n",
    "    N_it         = 20\n",
    "\n",
    "    # Assign 1. to the parameters to find\n",
    "    # init_length\n",
    "    if \"init_length\" in var_parameters_names:\n",
    "        init_length_bo = 1.\n",
    "    else:\n",
    "        init_length_bo = init_length \n",
    "\n",
    "    # length\n",
    "    if \"length\" in var_parameters_names:\n",
    "        length_bo = 1.\n",
    "    else:\n",
    "        length_bo = length # [mm]\n",
    "\n",
    "    # w\n",
    "    if \"w\" in var_parameters_names:\n",
    "        w_bo = 1.\n",
    "    else:\n",
    "        w_bo = w\n",
    "        \n",
    "    # l_segment\n",
    "    if \"l_segment\" in var_parameters_names:\n",
    "        l_segment_bo = 1.\n",
    "    else:\n",
    "        l_segment_bo = l_segment # [mm]\n",
    "\n",
    "    # fascicles_length\n",
    "    if \"fascicles_length\" in var_parameters_names:\n",
    "        f_len_bo = [1., 1.]\n",
    "    else:\n",
    "        f_len_bo = f_len\n",
    "\n",
    "    # f_angles\n",
    "    if \"fascicles_angles\" in var_parameters_names:\n",
    "        f_angles_bo = [1., 1.] \n",
    "    else:\n",
    "        f_angles_bo = f_angles\n",
    "\n",
    "    # branch_angle\n",
    "    if \"branch_angle\" in var_parameters_names:\n",
    "        branch_angle_bo = 1.\n",
    "    else:\n",
    "        branch_angle_bo = branch_angle\n",
    "\n",
    "    parameters_values = {\"patient\"         : patient,\n",
    "                         \"meshes_list\"     : meshes_list, \n",
    "                         \"init_length\"     : init_length_bo, \n",
    "                         \"length\"          : length_bo, \n",
    "                         \"w\"               : w_bo, \n",
    "                         \"l_segment\"       : l_segment_bo, \n",
    "                         \"fascicles_length\": f_len_bo, \n",
    "                         \"fascicles_angles\": f_angles_bo, \n",
    "                         \"branch_angle\"    : branch_angle_bo, \n",
    "                         \"N_it\"            : N_it,\n",
    "                         \"myocardium\"      : myocardium}\n",
    "    \n",
    "    return parameters_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_parameters_list = [\"init_length\", \"fascicles_length\", \"fascicles_angles\",\"root_time\", \"cv\"]\n",
    "# var_parameters_list = [\"init_length\", \"length\", \"w\", \"fascicles_length\", \"fascicles_angles\",\n",
    "#                        \"branch_angle\", \"root_time\", \"cv\"]\n",
    "\n",
    "#assert var_parameters_list == var_parameters_read, \"Variables do not match ground truth variables\"\n",
    "\n",
    "initial_params = initial_values(var_parameters_list, patient, meshes_list_pat, myo)\n",
    "Tree_bo        = BO_PurkinjeTree(**initial_params)\n",
    "bo_method      = BO_ecg(bo_purkinje_tree = Tree_bo)\n",
    "\n",
    "# f is the mse between real (ecg_pat_array) and computed ecg\n",
    "var_parameters = var_parameters_dict(var_parameters_list)\n",
    "f, p_x         = bo_method.mse_jaxbo(ground_truth = ecg_pat_array, variable_parameters = var_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4611294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dd5a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([74.12523435, 62.46094801, 24.19023292, 40.65849346, 32.69169548, 49.33628498,\n",
    "  1.08097521, -0.73921825,  0.74647183,  1.68333156, 12.50440764,  2.5114008 ])\n",
    "bo_method.st_dictionary_variables(bo_method.variable_parameters, list(onp.array(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08998656",
   "metadata": {},
   "outputs": [],
   "source": [
    "[float(a) for a in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0873f8ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if obtain_training_data == \"compute_points\":\n",
    "    print (\"Computing training points ...\")\n",
    "    t_ini_train = time.time()    \n",
    "\n",
    "    bo_method.y_trees_non_valid = 10.\n",
    "    noise                       = 0.0\n",
    "    X, y                        = bo_method.set_initial_training_data(N, noise)\n",
    "\n",
    "    onp.save(\"./output/patient\"+str(patient_number)+\"/data_X_\"+str(N)+\"_\"+\n",
    "                \"_\".join(list(var_parameters.keys())), X)\n",
    "    onp.save(\"./output/patient\"+str(patient_number)+\"/data_y_\"+str(N)+\"_\"+\n",
    "                \"_\".join(list(var_parameters.keys())), y)\n",
    "    onp.save(\"./output/patient\"+str(patient_number)+\"/data_noise_\"+str(N)+\"_\"+\n",
    "                \"_\".join(list(var_parameters.keys())), noise)\n",
    "    \n",
    "    t_fin_train = time.time()\n",
    "    print(f\"Train time: {t_fin_train - t_ini_train} s\")\n",
    "\n",
    "elif obtain_training_data == \"load_data\":\n",
    "    print (\"Loading training points ...\")\n",
    "\n",
    "    X     = np.load(\"./output/patient\"+str(patient_number)+\"/data_X_\"+str(N)+\"_\"+\n",
    "                \"_\".join(list(var_parameters.keys()))+\".npy\") \n",
    "    y     = np.load(\"./output/patient\"+str(patient_number)+\"/data_y_\"+str(N)+\"_\"+\n",
    "                \"_\".join(list(var_parameters.keys()))+\".npy\")\n",
    "    noise = np.load(\"./output/patient\"+str(patient_number)+\"/data_noise_\"+str(N)+\"_\"+\n",
    "                \"_\".join(list(var_parameters.keys()))+\".npy\")\n",
    "        \n",
    "    bo_method.noise = noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value for non-valid trees\n",
    "valid   = y != 10.\n",
    "y_valid = y[valid]\n",
    "\n",
    "bo_method.y_trees_non_valid = np.max(y_valid) # trees_non_valid \n",
    "\n",
    "mask = np.where(y == 10.)[0] # in saved files, non-valid trees are saved with y = 10.\n",
    "y    = y.at[mask].set(bo_method.y_trees_non_valid)\n",
    "print (f\"y_trees_non_valid = {bo_method.y_trees_non_valid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bo_method.dim == 2:\n",
    "    X_star, XX, YY = bo_method.set_test_data()\n",
    "else:\n",
    "    X_star = bo_method.set_test_data()\n",
    "\n",
    "# Global minimun is known\n",
    "true_x = list(var_params_true.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Bayesian optimization loop\n",
    "options = {'kernel'     : 'Matern12', # 'Matern52'\n",
    "           'criterion'  : criterion_bo, # EI: expected improvement; LW-LCB\n",
    "           'input_prior': p_x,\n",
    "           'kappa'      : 2.0,\n",
    "           'nIter'      : nIter}\n",
    "\n",
    "if optimization_points == \"run_opt\":\n",
    "    print (\"Running optimization ...\")\n",
    "    t_ini_opt = time.time()\n",
    "    \n",
    "    X, y, info_iterations = bo_method.bo_loop(X, y, X_star, true_x, options)\n",
    "    # mean_iterations, std_iterations, w_pred_iterations, a_pred_iterations = info_iterations\n",
    "    \n",
    "    t_fin_opt = time.time()\n",
    "    print (f\"Optimization time: {t_fin_opt - t_ini_opt} s\")\n",
    "    \n",
    "    # Save points obtained from optimization\n",
    "    onp.save(f\"./output/patient{patient_number}/data_X_N_{N}_nIter_{nIter}_criterion{criterion_bo}_\" + \n",
    "             \"_\".join(list(var_parameters.keys())), X)\n",
    "    \n",
    "    onp.save(f\"./output/patient{patient_number}/data_y_N_{N}_nIter_{nIter}_criterion{criterion_bo}_\" + \n",
    "             \"_\".join(list(var_parameters.keys())), y)    \n",
    "    \n",
    "elif optimization_points == \"load_opt_points\":\n",
    "    print (\"Loading optimization points ...\")\n",
    "    bo_method.nIter = nIter\n",
    "    \n",
    "    X = np.load(\"./output/patient\"+str(patient_number)+\"/data_X_N_\"+str(N)+\n",
    "                \"_nIter_\"+str(nIter)+\"_criterion\"+str(options[\"criterion\"])+\"_\"+\n",
    "                \"_\".join(list(var_parameters.keys()))+\".npy\")\n",
    "    \n",
    "    y = np.load(\"./output/patient\"+str(patient_number)+\"/data_y_N_\"+str(N)+\n",
    "                \"_nIter_\"+str(nIter)+\"_criterion\"+str(options[\"criterion\"])+\"_\"+\n",
    "                \"_\".join(list(var_parameters.keys()))+\".npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots of error\n",
    "list_variable_params = \"_\".join(list(var_parameters.keys()))\n",
    "file_name            = f\"./output/patient{patient_number}/BO_N{N}_nIter{nIter}_criterion\"+str(options[\"criterion\"])+ f\"_variableparams_{list_variable_params}\" \n",
    "\n",
    "plot_MSE = False\n",
    "\n",
    "if plot_MSE:\n",
    "    bo_method.plot_mse(X, y, N, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_bo, LVtree_bo, RVtree_bo = bo_method.update_purkinje_tree(X, y, var_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6f1ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_best = onp.argmin(y)\n",
    "best_x   = onp.array(X[idx_best,:])\n",
    "\n",
    "best_var_parameters = bo_method.set_dictionary_variables(var_parameters = var_parameters,\n",
    "                                                    x_values       = best_x)\n",
    "\n",
    "ecg_bo,  LVtree_bo, RVtree_bo = bo_method.bo_purkinje_tree.run_ECG(modify = True, side = 'both', **best_var_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f8ef1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_best_ecg = True\n",
    "\n",
    "if plot_best_ecg:\n",
    "    # Plot the best ecg found by the BO along with the reference ecg\n",
    "    bo_method.plot_ecg_match(predicted = ecg_bo, filename_match = file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tree\n",
    "bo_method.bo_purkinje_tree.myocardium.save_pv(file_name+\"_myo.vtu\")\n",
    "LVtree_bo.save(file_name+\"_LVtree.vtu\")\n",
    "RVtree_bo.save(file_name+\"_RVtree.vtu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pairplot_bo = False\n",
    "\n",
    "if plot_pairplot_bo:\n",
    "    # Create columns names for pairplot\n",
    "    df_columns = []\n",
    "    if \"init_length\" in var_parameters.keys():\n",
    "        df_columns += [\"In. Length L\", \"In. Length R\"]\n",
    "        \n",
    "    if \"length\" in var_parameters.keys():\n",
    "        df_columns += [\"Length\"]\n",
    "        \n",
    "    if \"w\" in var_parameters.keys():\n",
    "        df_columns += [\"w\"]\n",
    "        \n",
    "    if \"fascicles_length\" in var_parameters.keys():\n",
    "        df_columns += [\"Fas. Length L1\", \"Fas. Length L2\", \"Fas. Length R1\", \"Fas. Length R2\"]\n",
    "        \n",
    "    if \"fascicles_angles\" in var_parameters.keys():\n",
    "        df_columns += [\"Fas. Angle L1\", \"Fas. Angle L2\", \"Fas. Angle R1\", \"Fas. Angle R2\"]\n",
    "        \n",
    "    if \"branch_angle\" in var_parameters.keys():\n",
    "        df_columns += [\"Branch Angle\"]\n",
    "        \n",
    "    if \"root_time\" in var_parameters.keys():\n",
    "        df_columns += [\"Root time\"]\n",
    "        \n",
    "    if \"cv\" in var_parameters.keys():\n",
    "        df_columns += [\"CV\"]\n",
    "\n",
    "    # Create data frame with training + optimization points\n",
    "    df      = pd.DataFrame(X, columns = df_columns)\n",
    "    df[\"y\"] = y\n",
    "\n",
    "    # Discretize the continuous variable into bins\n",
    "    num_bins       = 5\n",
    "    bin_labels     = [f'Bin {i}' for i in range(1, num_bins + 1)]\n",
    "    df['hue_bins'] = pd.cut(df['y'], bins = num_bins, labels = bin_labels)\n",
    "\n",
    "    # Plot the pairplot with hue as the discretized variable\n",
    "    sns.pairplot(df, hue='hue_bins')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rejection sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_std_ybest_ecgs(X, y, qrs_in, qrs_fin, var_parameters, bo_class, ecg_patient):\n",
    "    print (f\"Find MSE_best curve ...\")\n",
    "\n",
    "    # Find L_best and std_best comparing y_best = min(y) with all ecgs\n",
    "    X_min            = X[np.argmin(y)]\n",
    "    ecg_min, _, _, _ = bo_class.update_purkinje_tree(np.array([X_min]), 1., var_parameters)\n",
    "    print (f\"X_min = {X_min}\")\n",
    "    print (f\"y_min = {np.min(y)}\")\n",
    "\n",
    "    # Compare with ecgs of all times (not with the mean of them, as previously)\n",
    "    mse_values_best = []\n",
    "    names           = list(ecg_patient.keys())\n",
    "    for ecg_ind in np.arange(ecg_patient[names[0]].shape[1]):\n",
    "\n",
    "        ecg_pat_ind = []\n",
    "        for items in list(ecg_patient.items()):\n",
    "            ecg_pat_ind.append(items[1][:,ecg_ind] / 1e3)\n",
    "\n",
    "        ecg_pat_array_ind = onp.rec.fromarrays(ecg_pat_ind, names=names)\n",
    "        ecg_pat_array_ind = ecg_pat_array_ind[qrs_in:qrs_fin]\n",
    "\n",
    "        mse_values_best.append(bo_class.calculate_loss(predicted = ecg_min,\n",
    "                                                       ecg_pat   = ecg_pat_array_ind))\n",
    "\n",
    "#     L_best_data   = np.mean(np.array(mse_values_best))\n",
    "#     std_best_data = np.std(np.array(mse_values_best))\n",
    "    return mse_values_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gp_model(X, y, options, bo_class, X_star_uniform, gp_state = None):\n",
    "    if gp_state is None:\n",
    "        print (\"Train GP model with valid points...\")\n",
    "        valid = y != bo_class.y_trees_non_valid\n",
    "\n",
    "        X_valid = X[valid]\n",
    "        y_valid = y[valid]\n",
    "        \n",
    "        print (f\"{len(X_valid)} valid points\")\n",
    "\n",
    "        rng_key = random.PRNGKey(0)\n",
    "        gp_model = GP(options)\n",
    "\n",
    "        # Fetch normalized training data\n",
    "        norm_batch, norm_const = normalize(X_valid, y_valid, bo_class.bounds)\n",
    "\n",
    "        # Train GP model\n",
    "        t_ini_train = time.time()\n",
    "        rng_key = random.split(rng_key)[0]\n",
    "        opt_params = gp_model.train(norm_batch,\n",
    "                                    rng_key,\n",
    "                                    num_restarts = 5)\n",
    "        t_fin_train = time.time()\n",
    "        print (f\"Training time: {t_fin_train - t_ini_train} s\")\n",
    "\n",
    "        kwargs = {'params': opt_params,\n",
    "                  'batch': norm_batch,\n",
    "                  'norm_const': norm_const,\n",
    "                  'bounds': bo_class.bounds}\n",
    "        #               'kappa': gp_model.options['kappa'],\n",
    "        #               'gmm_vars': gmm_vars,\n",
    "        #               'rng_key': rng_key}\n",
    "        \n",
    "        gp_state = [gp_model, [norm_batch, norm_const], kwargs]\n",
    "\n",
    "    else:\n",
    "        print (\"Re-using gp_model (it is not trained again with the new points X, y)...\")\n",
    "        gp_model               = gp_state[0]\n",
    "        norm_batch, norm_const = gp_state[1]\n",
    "        kwargs                 = gp_state[2]\n",
    "        \n",
    "    # Compute predicted mean and std\n",
    "    t_ini_pred = time.time()\n",
    "\n",
    "    # batches\n",
    "    n_col = 100\n",
    "    assert (len(X_star_uniform)/n_col).is_integer(), \"Modify n_col\"\n",
    "\n",
    "    reshaped_X      = [X_star_uniform[i:i+n_col] for i in range(0, len(X_star_uniform), n_col)]\n",
    "    mean_it, std_it = lax.map(lambda x: gp_model.predict(x, **kwargs),np.array(reshaped_X))\n",
    "    mean_it         = mean_it.reshape((1,-1))[0]\n",
    "    std_it          = std_it.reshape((1,-1))[0]\n",
    "\n",
    "    # # full\n",
    "    # mean_it, std_it = gp_model.predict(X_star_uniform, **kwargs)\n",
    "\n",
    "    t_fin_pred = time.time()\n",
    "    print (f\"Predicting time: {t_fin_pred - t_ini_pred} s\")\n",
    "    \n",
    "    # Obtain ys and sigmas of X_star_uniform (test points with uniform sampling)\n",
    "    ys     = mean_it * norm_const[\"sigma_y\"] + norm_const[\"mu_y\"]\n",
    "    sigmas = std_it * norm_const[\"sigma_y\"]\n",
    "    \n",
    "    # Obtain min values predicted by gp model\n",
    "    X_min             = X[np.argmin(y)]\n",
    "    mean_min, std_min = gp_model.predict(X_min[None,:], **kwargs)\n",
    "\n",
    "    y_gp_best     = mean_min * norm_const[\"sigma_y\"] + norm_const[\"mu_y\"]\n",
    "    sigma_gp_best = std_min * norm_const[\"sigma_y\"] # should be low\n",
    "    \n",
    "    return ys, sigmas, y_gp_best, sigma_gp_best, gp_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rejection_sampling(ys, sigmas, y_gp_best, sigma_gp_best):\n",
    "    # Rejection sampling, the likelihood is obtained comparing with best point\n",
    "\n",
    "    max_likelihood = norm.pdf(x     = 0.,\n",
    "                              loc   = 0.,\n",
    "                              scale = np.sqrt(sigma_gp_best**2 + np.min(sigmas)**2))\n",
    "\n",
    "    key        = random.PRNGKey(0) # onp.random.randint(50)\n",
    "    comparison = random.uniform(key, shape = (ys.shape[0],)) * max_likelihood\n",
    "\n",
    "    likelihoods = norm.pdf(x     = 0.,\n",
    "                           loc   = ys - y_gp_best,\n",
    "                           scale = np.sqrt(sigmas**2 + sigma_gp_best**2))\n",
    "     \n",
    "    accepted_samples = likelihoods > comparison    \n",
    "\n",
    "    print(f\"{accepted_samples.sum()} accepted samples\")\n",
    "    return accepted_samples, comparison, likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d159f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_candidate(args):\n",
    "    x_accepted, comp, bo_class, var_parameters, y_gp_best, tol = args\n",
    "    try:\n",
    "        # Simulate the Purkinje tree and ECG\n",
    "        ecg_i, endo_i, LVtree_i, RVtree_i = bo_class.update_purkinje_tree(\n",
    "            np.array([x_accepted]), 1.0, var_parameters\n",
    "        )\n",
    "\n",
    "        # Calculate the ECG loss\n",
    "        loss_i, ind_loss_i = bo_class.calculate_loss(\n",
    "            predicted=ecg_i,\n",
    "            cross_correlation=True,\n",
    "            return_ind=True\n",
    "        )\n",
    "\n",
    "        y_true = loss_i\n",
    "        accepted = (y_true - y_gp_best) < tol\n",
    "\n",
    "        return {\n",
    "            \"x\": x_accepted,\n",
    "            \"accepted\": accepted,\n",
    "            \"y_true\": y_true,\n",
    "            \"ecg\": ecg_i,\n",
    "            \"endo\": endo_i,\n",
    "            \"LVtree\": LVtree_i,\n",
    "            \"RVtree\": RVtree_i,\n",
    "            \"loss\": loss_i,\n",
    "            \"ind_loss\": ind_loss_i,\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        # Failed simulation (likely out of domain)\n",
    "        return {\n",
    "            \"x\": x_accepted,\n",
    "            \"accepted\": False,\n",
    "            \"y_true\": bo_class.y_trees_non_valid,\n",
    "            \"ecg\": None,\n",
    "            \"endo\": None,\n",
    "            \"LVtree\": None,\n",
    "            \"RVtree\": None,\n",
    "            \"loss\": None,\n",
    "            \"ind_loss\": None,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2810057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accepted_samples(N_samples, X_star_uniform, y_gp_best, accepted_samples, comparison, likelihoods,\n",
    "                           var_parameters, bo_class, tol, observed_samples, confirmed_samples, folder_trees):\n",
    "    import time\n",
    "\n",
    "    X_accepted = X_star_uniform[accepted_samples]\n",
    "    comparison_accepted = comparison[accepted_samples]\n",
    "    likelihoods_accepted = likelihoods[accepted_samples]\n",
    "\n",
    "    # Sort by likelihood\n",
    "    sorted_indices = np.argsort(-likelihoods_accepted)\n",
    "    X_accepted = X_accepted[sorted_indices]\n",
    "    comparison_accepted = comparison_accepted[sorted_indices]\n",
    "\n",
    "    # Ensure confirmed_samples is initialized\n",
    "    if len(confirmed_samples) == 0:\n",
    "        confirmed_samples[\"samples_final\"] = []\n",
    "        confirmed_samples[\"ecg_final\"] = []\n",
    "        confirmed_samples[\"Tree_final\"] = []\n",
    "        confirmed_samples[\"loss_final\"] = []\n",
    "\n",
    "    # Prepare arguments for parallel execution\n",
    "    args = [(x, c, bo_class, var_parameters, y_gp_best, tol) for x, c in zip(X_accepted, comparison_accepted)]\n",
    "\n",
    "    print(f\"tolerance: {tol}\")\n",
    "    print(f\"Evaluating {len(args)} candidates in parallel...\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    results = []\n",
    "    with Pool(processes=6) as pool:\n",
    "        results = pool.map(evaluate_candidate, args)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Parallel evaluation took {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    # Now loop through results and update confirmed/observed state\n",
    "    X_true_new = []\n",
    "    Y_true_new = []\n",
    "    state = []\n",
    "    observed_samples_new = []\n",
    "\n",
    "    for idx, res in enumerate(results):\n",
    "        x_accepted = res[\"x\"]\n",
    "\n",
    "        # Check for duplicates\n",
    "        if any(np.array_equal(obs[0], x_accepted) for obs in observed_samples):\n",
    "            print(f\"Point {idx+1}/{len(results)} already observed\")\n",
    "            continue\n",
    "\n",
    "        if res[\"ecg\"] is None:\n",
    "            print(f\"Point {idx+1}: rejected (invalid geometry)\")\n",
    "            state.append(\"rejected\")\n",
    "            X_true_new.append(x_accepted)\n",
    "            Y_true_new.append(res[\"y_true\"])\n",
    "            observed_samples_new.append([x_accepted, \"non_valid\"])\n",
    "            continue\n",
    "\n",
    "        # Record result\n",
    "        X_true_new.append(x_accepted)\n",
    "        Y_true_new.append(res[\"y_true\"])\n",
    "        observed_samples_new.append([x_accepted, [\n",
    "            res[\"ecg\"], res[\"endo\"], res[\"LVtree\"], res[\"RVtree\"],\n",
    "            res[\"loss\"], res[\"ind_loss\"]\n",
    "        ]])\n",
    "\n",
    "        print(f\"Point {idx+1}: Loss = {res['loss']}, Δ = {res['y_true'] - y_gp_best}\")\n",
    "\n",
    "        if res[\"accepted\"]:\n",
    "            print(f\"Sample accepted! ({len(confirmed_samples['samples_final'])+1}/{N_samples})\")\n",
    "            state.append(\"accepted\")\n",
    "            confirmed_samples[\"samples_final\"].append(x_accepted)\n",
    "            confirmed_samples[\"ecg_final\"].append([res[\"ecg\"], res[\"ind_loss\"]])\n",
    "            confirmed_samples[\"Tree_final\"].append([res[\"LVtree\"], res[\"RVtree\"]])\n",
    "            confirmed_samples[\"loss_final\"].append(res[\"loss\"])\n",
    "\n",
    "            tree_ind_test = len(confirmed_samples[\"samples_final\"]) - 1\n",
    "\n",
    "            if len(confirmed_samples[\"samples_final\"]) >= N_samples:\n",
    "                return \"ok\", confirmed_samples\n",
    "        else:\n",
    "            print(\"Sample rejected\")\n",
    "            state.append(\"rejected\")\n",
    "\n",
    "        # Early stopping if too many consecutive rejections\n",
    "        n_rej_max = 50\n",
    "        if len(state) >= n_rej_max and state[-n_rej_max:] == [\"rejected\"] * n_rej_max:\n",
    "            print(f\"No samples accepted in last {n_rej_max} iterations\")\n",
    "            break\n",
    "\n",
    "    print(f\"Elapsed time: {time.time() - start_time:.2f} seconds\")\n",
    "    print(f\"Total accepted samples: {len(confirmed_samples['samples_final'])}\")\n",
    "\n",
    "    info_final = {\n",
    "        \"X_true_new\": X_true_new,\n",
    "        \"Y_true_new\": Y_true_new,\n",
    "        \"Observed_samples\": observed_samples + observed_samples_new,\n",
    "        \"Confirmed_samples\": confirmed_samples\n",
    "    }\n",
    "\n",
    "    return \"retrain gp\", info_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop for finding and accepting \"N_samples\" candidates\n",
    "options = {'kernel'     : 'Matern12', # 'Matern52'\n",
    "           'criterion'  : criterion_bo, # EI: expected improvement; LW-LCB\n",
    "           'input_prior': p_x,\n",
    "           'kappa'      : 2.0,\n",
    "           'nIter'      : nIter}\n",
    "\n",
    "nn           = 500000 # test points\n",
    "N_samples    = 30 # 2 #\n",
    "tol          = 100.\n",
    "rejection_n  = 1\n",
    "gp_rejection = None\n",
    "obs_samples  = []\n",
    "conf_samples = {}\n",
    "\n",
    "# Folder to save trees\n",
    "folder_trees = f\"/Trees_N{N}_nIter{nIter}_criterion{criterion_bo}_variableparams_{list_variable_params}\"\n",
    "if os.path.exists(f\"./output/patient{patient_number}\"+folder_trees):\n",
    "    shutil.rmtree(f\"./output/patient{patient_number}\"+folder_trees)\n",
    "\n",
    "os.makedirs(f\"./output/patient{patient_number}\"+folder_trees)\n",
    "\n",
    "while True:\n",
    "    print (\"\")\n",
    "    print (f\"Rejection loop {rejection_n}\")\n",
    "\n",
    "    y_best = np.min(y)\n",
    "    \n",
    "    # Uniform sampling\n",
    "    key        = random.PRNGKey(rejection_n - 1) # 0\n",
    "    X_star_uni = bo_method.lb_params + (bo_method.ub_params - bo_method.lb_params) * random.uniform(key, shape = (nn, bo_method.dim))\n",
    "\n",
    "    # Train with valid points\n",
    "    ys, sigmas, y_gp_best, sigma_gp_best, gp_rejection = train_gp_model(X,\n",
    "                                                                        y,\n",
    "                                                                        options,\n",
    "                                                                        bo_class       = bo_method,\n",
    "                                                                        X_star_uniform = X_star_uni,\n",
    "                                                                        gp_state       = None) # gp_rejection (to not re-train in each loop)\n",
    "\n",
    "    accepted_samples, comparison, likelihoods = rejection_sampling(ys,\n",
    "                                                                   sigmas,\n",
    "                                                                   y_gp_best,\n",
    "                                                                   sigma_gp_best)\n",
    "\n",
    "    state_final, info_final = check_accepted_samples(N_samples         = N_samples,\n",
    "                                                     X_star_uniform    = X_star_uni,\n",
    "                                                     y_gp_best         = y_gp_best,\n",
    "                                                     accepted_samples  = accepted_samples,\n",
    "                                                     comparison        = comparison,\n",
    "                                                     likelihoods       = likelihoods,\n",
    "                                                     var_parameters    = var_parameters,\n",
    "                                                     bo_class          = bo_method,\n",
    "                                                     tol               = tol,\n",
    "                                                     observed_samples  = obs_samples,\n",
    "                                                     confirmed_samples = conf_samples,\n",
    "                                                     folder_trees      = folder_trees)\n",
    "    \n",
    "    if state_final == \"ok\":\n",
    "        samples_final  = info_final[\"samples_final\"]\n",
    "        ecg_final      = info_final[\"ecg_final\"]\n",
    "#         endo_final = info_final[\"endo_final\"]\n",
    "        Tree_final     = info_final[\"Tree_final\"]\n",
    "        loss_final     = info_final[\"loss_final\"]\n",
    "\n",
    "        onp.save(f\"./output/patient{patient_number}/rejection_X_N_{N}_nIter_{nIter}_criterion_{criterion_bo}_nn_{nn}_tol_{tol}_rejection_n_{rejection_n}\", X)\n",
    "        onp.save(f\"./output/patient{patient_number}/rejection_y_N_{N}_nIter_{nIter}_criterion_{criterion_bo}_nn_{nn}_tol_{tol}_rejection_n_{rejection_n}\", y)\n",
    "        \n",
    "        # Save all files now that we have accepted samples\n",
    "        for i, ((LVtree, RVtree), (ecg, ind_loss)) in enumerate(zip(Tree_final, ecg_final)):\n",
    "            LVtree.save(f\"./output/patient{patient_number}{folder_trees}/LVtree_N{N}_nIter{nIter}_criterion{options['criterion']}_{i}.vtu\")\n",
    "            RVtree.save(f\"./output/patient{patient_number}{folder_trees}/RVtree_N{N}_nIter{nIter}_criterion{options['criterion']}_{i}.vtu\")\n",
    "            ecg[1].save_pv(f\"./output/patient{patient_number}{folder_trees}/propeiko_N{N}_nIter{nIter}_criterion{options['criterion']}_{i}.vtu\")\n",
    "\n",
    "\n",
    "        break\n",
    "        \n",
    "    elif state_final == \"retrain gp\":\n",
    "        obs_samples  = info_final[\"Observed_samples\"]\n",
    "        conf_samples = info_final[\"Confirmed_samples\"]        \n",
    "        \n",
    "        X_new = info_final[\"X_true_new\"]\n",
    "        y_new = info_final[\"Y_true_new\"]\n",
    "        y_new = np.asarray(y_new)\n",
    "        \n",
    "        X = np.concatenate([X, np.array(X_new)], axis = 0)\n",
    "        y = np.concatenate([y, y_new], axis = 0)\n",
    "        \n",
    "        assert len(X_new) == len(y_new), \"Something is wrong\"\n",
    "        print (f\"Retrain the gp model with {len(X_new)} new points\")\n",
    "\n",
    "    if rejection_n == 50:\n",
    "        onp.save(f\"./output/patient{patient_number}/rejection_X_N_{N}_nIter_{nIter}_criterion_{criterion_bo}_nn_{nn}_tol_{tol}_rejection_n_{rejection_n}\", X)\n",
    "        onp.save(f\"./output/patient{patient_number}/rejection_y_N_{N}_nIter_{nIter}_criterion_{criterion_bo}_nn_{nn}_tol_{tol}_rejection_n_{rejection_n}\", y)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(\"Elapsed time: \" + str(end_time - start_time))\n",
    "        raise Exception(f\"It was not possible to find and check {N_samples} samples\")\n",
    "    \n",
    "    rejection_n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_final = True\n",
    "\n",
    "if save_final:\n",
    "    pickle.dump(ecg_final, open(f\"./output/patient{patient_number}/ecg_N{N}_nIter{nIter}_criterion{criterion_bo}_variableparams_{list_variable_params}\",\"wb\"))\n",
    "    onp.save(f\"./output/patient{patient_number}/X_final_N{N}_nIter{nIter}_criterion{criterion_bo}_variableparams_{list_variable_params}.npy\",samples_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "print(f\"Elapsed time: {end_time - start_time} s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
